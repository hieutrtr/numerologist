# Story 1.2d: Daily.co Bot Participant for Voice Stream Processing

**Status:** Planning
**Priority:** P0 - Critical
**Story Points:** 13
**Dependencies:** Story 1.2c (Daily.co Frontend Integration - Complete)

## Overview

Implement a Daily.co bot participant in the backend that joins voice rooms, receives real-time audio streams from users, processes them through Azure OpenAI STT, sends to AI agent for numerology analysis, and responds with synthesized voice via ElevenLabs TTS.

## Problem Statement

Currently, the backend can create Daily.co rooms and generate tokens, but **cannot receive or process audio streams**. The frontend is ready to send audio via Daily.co WebRTC, but there's no backend participant to receive it.

**Current Gap:**
```
Frontend (Ready) → Daily.co Room (Created) → [NO BOT TO RECEIVE AUDIO] ❌
```

**Required Flow:**
```
Frontend → Daily.co Room → Backend Bot Participant → STT → AI Agent → TTS → Response ✅
```

## Acceptance Criteria

### 1. Daily.co Bot Service Implementation
- [ ] `DailyBotService` class that manages bot lifecycle
- [ ] Bot joins Daily.co room when conversation starts
- [ ] Bot leaves room when conversation ends
- [ ] Bot handles reconnection on network failures
- [ ] Proper cleanup of resources (memory, connections)

### 2. Audio Stream Reception
- [ ] Bot receives real-time audio chunks from user's microphone
- [ ] Audio chunks are buffered appropriately (e.g., 1-second windows)
- [ ] Handles multiple concurrent conversations (one bot per room)
- [ ] Audio format conversion if needed (Daily.co format → Azure OpenAI format)

### 3. Speech-to-Text Integration
- [ ] Audio chunks sent to Azure OpenAI `gpt-4o-mini-transcribe` deployment
- [ ] Streaming transcription (partial results before sentence completion)
- [ ] Final transcription with confidence score
- [ ] Handles Vietnamese language correctly
- [ ] Error handling for STT failures (network, quota limits)

### 4. AI Agent Processing
- [ ] Transcribed text sent to Microsoft Agent Framework
- [ ] Agent uses numerology tools to calculate insights
- [ ] Agent generates Vietnamese response text
- [ ] Conversation context maintained across turns

### 5. Text-to-Speech Response
- [ ] Response text sent to ElevenLabs TTS
- [ ] Vietnamese voice synthesis with request stitching
- [ ] Audio response sent back through Daily.co room
- [ ] User receives audio in real-time

### 6. Conversation State Management
- [ ] Track conversation state: `waiting`, `listening`, `processing`, `responding`
- [ ] Store transcriptions and responses in database
- [ ] Cache conversation context in Redis
- [ ] Handle user interruptions (user starts speaking while bot is responding)

### 7. Error Handling & Recovery
- [ ] Graceful handling of Daily.co connection failures
- [ ] Retry logic for Azure OpenAI API failures
- [ ] Fallback messages when TTS fails
- [ ] Logging and monitoring for debugging

### 8. Performance Requirements
- [ ] End-to-end latency < 3 seconds (user speech → bot response)
- [ ] Support up to 10 concurrent conversations
- [ ] Audio quality: 16kHz sample rate minimum
- [ ] Memory usage < 500MB per bot instance

## Technical Specification

### Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                         FastAPI Backend                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                   │
│  ┌────────────────────────────────────────────────────────┐    │
│  │              DailyBotService                            │    │
│  │  - create_bot_for_room(room_url, conversation_id)      │    │
│  │  - destroy_bot(conversation_id)                         │    │
│  │  - get_bot_status(conversation_id)                      │    │
│  └───────────────────┬────────────────────────────────────┘    │
│                      │                                           │
│  ┌───────────────────▼────────────────────────────────────┐    │
│  │         DailyBotParticipant (per conversation)          │    │
│  │  - join_room(room_url, token)                           │    │
│  │  - on_participant_joined(participant)                   │    │
│  │  - on_audio_data(audio_chunk) ←────────────┐           │    │
│  │  - on_participant_left(participant)         │           │    │
│  │  - leave_room()                             │           │    │
│  └─────────────────────────────────────────────┼───────────┘    │
│                                                 │                │
│                                    ┌────────────▼──────────┐    │
│                                    │  Audio Buffer         │    │
│                                    │  (1-second windows)   │    │
│                                    └────────────┬──────────┘    │
│                                                 │                │
│  ┌──────────────────────────────────────────────▼─────────┐    │
│  │         VoiceProcessingPipeline                         │    │
│  │  1. Buffer audio → STT (Azure OpenAI)                   │    │
│  │  2. Transcription → Agent (Microsoft Agent Framework)   │    │
│  │  3. Response text → TTS (ElevenLabs)                    │    │
│  │  4. Audio response → send_to_room()                     │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                   │
└─────────────────────────────────────────────────────────────────┘

         ▲                                             │
         │                                             ▼
    ┌────┴─────┐                              ┌────────────┐
    │  Daily.co │◄────WebRTC Audio────────────│  Frontend  │
    │    SFU    │                              │  (Mobile)  │
    └──────────┘                               └────────────┘
```

### Technology Stack

**Daily.co Integration:**
- **Package:** `daily-python` (official Python SDK)
- **Installation:** `pip install daily-python`
- **Documentation:** https://docs.daily.co/reference/daily-python

**Key Components:**
- `Daily` class: Main client for joining rooms
- `EventHandler`: Base class for handling Daily.co events
- `CallClient`: Manages call connection and media streams

**Alternative Options Considered:**
1. ❌ **Daily.co REST API only** - Cannot receive audio streams (REST is for management only)
2. ❌ **Daily.co Prebuilt** - No control over audio processing pipeline
3. ✅ **Daily.co Python SDK** - Full control, handles WebRTC complexity

### Core Classes

#### 1. DailyBotService (Singleton)

```python
# apps/api/src/services/daily_bot_service.py

from typing import Dict, Optional
from daily import Daily, CallClient, EventHandler
import asyncio

class DailyBotService:
    """
    Manages Daily.co bot participants for voice conversations.
    One bot per conversation room.
    """

    def __init__(self):
        self._bots: Dict[str, DailyBotParticipant] = {}
        self._lock = asyncio.Lock()

    async def create_bot_for_room(
        self,
        room_url: str,
        conversation_id: str,
        token: Optional[str] = None
    ) -> DailyBotParticipant:
        """
        Create and start a bot participant for a conversation room.

        Args:
            room_url: Daily.co room URL
            conversation_id: Conversation ID for tracking
            token: Optional meeting token

        Returns:
            DailyBotParticipant instance
        """
        async with self._lock:
            if conversation_id in self._bots:
                return self._bots[conversation_id]

            bot = DailyBotParticipant(
                room_url=room_url,
                conversation_id=conversation_id,
                token=token
            )
            await bot.start()
            self._bots[conversation_id] = bot
            return bot

    async def destroy_bot(self, conversation_id: str) -> None:
        """Cleanup and remove bot for conversation."""
        async with self._lock:
            if conversation_id in self._bots:
                bot = self._bots[conversation_id]
                await bot.stop()
                del self._bots[conversation_id]

    def get_bot(self, conversation_id: str) -> Optional[DailyBotParticipant]:
        """Get bot instance for conversation."""
        return self._bots.get(conversation_id)

# Global singleton instance
daily_bot_service = DailyBotService()
```

#### 2. DailyBotParticipant (Per Conversation)

```python
# apps/api/src/services/daily_bot_participant.py

from daily import CallClient, Daily, EventHandler
from typing import Optional
import asyncio
import logging

logger = logging.getLogger(__name__)

class DailyBotParticipant(EventHandler):
    """
    Daily.co bot participant that joins room and processes audio.
    One instance per conversation.
    """

    def __init__(
        self,
        room_url: str,
        conversation_id: str,
        token: Optional[str] = None
    ):
        super().__init__()
        self.room_url = room_url
        self.conversation_id = conversation_id
        self.token = token

        self.client: Optional[CallClient] = None
        self.pipeline: Optional[VoiceProcessingPipeline] = None
        self.is_running = False

    async def start(self) -> None:
        """Join Daily.co room and start listening."""
        try:
            # Create Daily client
            self.client = CallClient(event_handler=self)

            # Join room
            join_config = {"url": self.room_url}
            if self.token:
                join_config["token"] = self.token

            await self.client.join(**join_config)

            # Initialize processing pipeline
            self.pipeline = VoiceProcessingPipeline(
                conversation_id=self.conversation_id,
                client=self.client
            )

            self.is_running = True
            logger.info(f"Bot joined room for conversation {self.conversation_id}")

        except Exception as e:
            logger.error(f"Failed to start bot: {e}")
            raise

    async def stop(self) -> None:
        """Leave room and cleanup resources."""
        try:
            self.is_running = False

            if self.pipeline:
                await self.pipeline.cleanup()

            if self.client:
                await self.client.leave()
                await self.client.release()

            logger.info(f"Bot left room for conversation {self.conversation_id}")

        except Exception as e:
            logger.error(f"Error stopping bot: {e}")

    # ===== Daily.co Event Handlers =====

    async def on_participant_joined(self, participant):
        """Called when a participant joins the room."""
        logger.info(f"Participant joined: {participant['user_name']}")

    async def on_participant_left(self, participant, reason):
        """Called when a participant leaves the room."""
        logger.info(f"Participant left: {participant['user_name']}")

    async def on_app_message(self, message, sender):
        """Handle app messages from frontend."""
        logger.info(f"App message from {sender}: {message}")

        if message.get("type") == "user_input_started":
            # User started speaking
            if self.pipeline:
                await self.pipeline.on_user_started_speaking()

        elif message.get("type") == "user_input_ended":
            # User stopped speaking
            if self.pipeline:
                await self.pipeline.on_user_stopped_speaking()

    async def on_audio_data(self, audio_data):
        """
        Called when audio data is received from participant.
        This is the core method that receives voice chunks!

        Args:
            audio_data: Dict with audio buffer, sample_rate, etc.
        """
        if not self.is_running or not self.pipeline:
            return

        # Process audio through pipeline
        await self.pipeline.process_audio_chunk(audio_data)

    async def on_error(self, error):
        """Handle errors from Daily.co."""
        logger.error(f"Daily.co error: {error}")
```

#### 3. VoiceProcessingPipeline

```python
# apps/api/src/services/voice_processing_pipeline.py

import asyncio
import numpy as np
from typing import Optional
import logging

from .voice_service import voice_service
from .agent_service import agent_service
from .text_to_speech_service import tts_service

logger = logging.getLogger(__name__)

class VoiceProcessingPipeline:
    """
    Processes audio chunks through STT → Agent → TTS pipeline.
    """

    def __init__(self, conversation_id: str, client):
        self.conversation_id = conversation_id
        self.client = client  # Daily CallClient for sending audio back

        # Audio buffering
        self.audio_buffer = []
        self.buffer_duration_ms = 1000  # 1 second windows
        self.sample_rate = 16000

        # State
        self.is_user_speaking = False
        self.is_processing = False

    async def on_user_started_speaking(self) -> None:
        """User started speaking - prepare to receive audio."""
        self.is_user_speaking = True
        self.audio_buffer.clear()
        logger.info(f"[{self.conversation_id}] User started speaking")

    async def on_user_stopped_speaking(self) -> None:
        """User stopped speaking - process buffered audio."""
        self.is_user_speaking = False
        logger.info(f"[{self.conversation_id}] User stopped speaking")

        if self.audio_buffer:
            await self._process_complete_utterance()

    async def process_audio_chunk(self, audio_data: dict) -> None:
        """
        Process incoming audio chunk.

        Args:
            audio_data: {
                'buffer': bytes,  # Raw audio data
                'sample_rate': int,  # e.g., 16000
                'num_channels': int,  # e.g., 1 (mono)
                'participant_id': str
            }
        """
        if not self.is_user_speaking:
            return

        # Append to buffer
        self.audio_buffer.append(audio_data['buffer'])

        # Calculate total duration
        total_samples = sum(len(chunk) for chunk in self.audio_buffer) / 2  # 16-bit
        duration_ms = (total_samples / self.sample_rate) * 1000

        # Process when buffer reaches threshold
        if duration_ms >= self.buffer_duration_ms:
            await self._process_audio_segment()

    async def _process_audio_segment(self) -> None:
        """Process buffered audio segment through STT."""
        if self.is_processing:
            return

        self.is_processing = True

        try:
            # Combine audio chunks
            audio_bytes = b''.join(self.audio_buffer)
            self.audio_buffer.clear()

            # Send to Azure OpenAI STT (streaming)
            async def audio_stream():
                yield audio_bytes

            transcription = None
            async for result in voice_service.transcribe_audio_stream(audio_stream()):
                transcription = result
                # Could send partial transcription to frontend here
                await self._send_app_message({
                    "type": "transcription_update",
                    "text": result.text,
                    "is_final": False
                })

            # Log final transcription
            if transcription:
                logger.info(f"[{self.conversation_id}] Transcription: {transcription.text}")

        except Exception as e:
            logger.error(f"Error processing audio: {e}")

        finally:
            self.is_processing = False

    async def _process_complete_utterance(self) -> None:
        """Process complete user utterance through full pipeline."""
        try:
            # Combine all buffered audio
            audio_bytes = b''.join(self.audio_buffer)
            self.audio_buffer.clear()

            # 1. Speech-to-Text
            logger.info(f"[{self.conversation_id}] Running STT...")
            async def audio_stream():
                yield audio_bytes

            transcription = None
            async for result in voice_service.transcribe_audio_stream(audio_stream()):
                transcription = result

            if not transcription or not transcription.text:
                logger.warning(f"[{self.conversation_id}] Empty transcription")
                return

            user_text = transcription.text
            logger.info(f"[{self.conversation_id}] User said: {user_text}")

            # Send transcription to frontend
            await self._send_app_message({
                "type": "transcription_update",
                "text": user_text,
                "is_final": True
            })

            # 2. AI Agent Processing
            logger.info(f"[{self.conversation_id}] Processing with agent...")
            await self._send_app_message({
                "type": "processing_status",
                "status": "thinking"
            })

            # Get response from agent (numerology analysis)
            # TODO: Integrate with agent_service
            agent_response = await self._get_agent_response(user_text)

            logger.info(f"[{self.conversation_id}] Agent response: {agent_response}")

            # 3. Text-to-Speech
            logger.info(f"[{self.conversation_id}] Generating speech...")
            await self._send_app_message({
                "type": "processing_status",
                "status": "generating_audio"
            })

            audio_response = await tts_service.synthesize_speech(agent_response)

            # 4. Send audio back through Daily.co
            await self._send_audio_to_room(audio_response)

            # Send completion message
            await self._send_app_message({
                "type": "assistant_response",
                "text": agent_response,
                "status": "complete"
            })

        except Exception as e:
            logger.error(f"Error processing utterance: {e}")
            await self._send_app_message({
                "type": "error",
                "message": "Xin lỗi, đã có lỗi xảy ra. Vui lòng thử lại."
            })

    async def _get_agent_response(self, user_text: str) -> str:
        """Get response from AI agent."""
        # TODO: Integrate with Microsoft Agent Framework
        # For now, return placeholder
        return f"Tôi đã nghe bạn nói: {user_text}"

    async def _send_audio_to_room(self, audio_bytes: bytes) -> None:
        """Send audio response back through Daily.co room."""
        # Daily.co audio API
        # TODO: Implement audio sending through Daily CallClient
        logger.info(f"[{self.conversation_id}] Sending audio response")

    async def _send_app_message(self, message: dict) -> None:
        """Send app message to frontend participants."""
        if self.client:
            await self.client.send_app_message(message)

    async def cleanup(self) -> None:
        """Cleanup pipeline resources."""
        self.audio_buffer.clear()
        self.is_user_speaking = False
        self.is_processing = False
```

### API Changes

#### Updated Conversation Routes

```python
# apps/api/src/routes/conversations.py

from ..services.daily_bot_service import daily_bot_service

@router.post('/daily/room', response_model=DailyRoomResponse)
async def create_daily_conversation(
    user_id: str = Header(..., alias='x-user-id'),
    db: AsyncSession = Depends(get_db),
    redis = Depends(get_redis_client),
) -> DailyRoomResponse:
    """
    Create Daily.co room and start bot participant.
    """
    # Create room and conversation
    service = ConversationService(db, redis)
    result = await service.create_conversation_with_daily(user_id)

    # Start bot participant
    bot = await daily_bot_service.create_bot_for_room(
        room_url=result["room_url"],
        conversation_id=result["conversation_id"],
        token=None  # Bot doesn't need user token
    )

    return DailyRoomResponse(**result)

@router.patch('/{conversation_id}', response_model=ConversationResponse)
async def end_conversation(
    conversation_id: str,
    request: EndConversationRequest,
    user_id: str = Header(..., alias='x-user-id'),
    db: AsyncSession = Depends(get_db),
    redis = Depends(get_redis_client),
) -> ConversationResponse:
    """
    End conversation and cleanup bot.
    """
    # Destroy bot participant
    await daily_bot_service.destroy_bot(conversation_id)

    # End conversation in database
    service = ConversationService(db, redis)
    result = await service.end_conversation(
        conversation_id,
        user_id,
        request.rating,
    )
    return result
```

### Database Schema Changes

No schema changes required - existing conversation and message tables sufficient.

### Configuration

```python
# apps/api/src/config.py

class Settings(BaseSettings):
    # ... existing settings ...

    # Daily.co Configuration
    daily_api_key: str = Field(..., env="DAILY_API_KEY")
    daily_domain: Optional[str] = Field(None, env="DAILY_DOMAIN")  # Optional custom domain
```

### Environment Variables

```bash
# .env
DAILY_API_KEY=your_daily_api_key_here
DAILY_DOMAIN=your-domain.daily.co  # Optional
```

## Implementation Plan

### Phase 1: Foundation (Days 1-2)

**Goal:** Set up Daily.co bot infrastructure

- [ ] Install `daily-python` package
- [ ] Create `DailyBotService` singleton class
- [ ] Create `DailyBotParticipant` event handler
- [ ] Implement bot lifecycle (join/leave room)
- [ ] Add configuration and environment variables
- [ ] Write unit tests for bot service

**Deliverable:** Bot can join and leave rooms

### Phase 2: Audio Reception (Days 3-4)

**Goal:** Receive and buffer audio chunks

- [ ] Implement `on_audio_data()` event handler
- [ ] Create audio buffering logic (1-second windows)
- [ ] Handle audio format conversion if needed
- [ ] Add logging for audio reception
- [ ] Test with mock audio data

**Deliverable:** Bot receives and buffers audio chunks

### Phase 3: STT Integration (Days 5-6)

**Goal:** Process audio through Azure OpenAI STT

- [ ] Create `VoiceProcessingPipeline` class
- [ ] Integrate with existing `voice_service`
- [ ] Implement streaming transcription
- [ ] Add transcription result caching
- [ ] Handle STT errors and retries

**Deliverable:** Bot transcribes user speech to text

### Phase 4: Agent Integration (Days 7-8)

**Goal:** Process transcriptions through AI agent

- [ ] Integrate with existing `agent_service`
- [ ] Implement conversation context management
- [ ] Handle agent tool calls (numerology calculations)
- [ ] Store messages in database
- [ ] Add agent response caching

**Deliverable:** Bot generates intelligent responses

### Phase 5: TTS Integration (Days 9-10)

**Goal:** Convert responses to speech

- [ ] Integrate with existing `tts_service`
- [ ] Implement audio response sending via Daily.co
- [ ] Add request stitching for voice consistency
- [ ] Handle TTS errors and fallbacks

**Deliverable:** Bot speaks responses back to user

### Phase 6: State Management (Days 11-12)

**Goal:** Handle conversation state and interruptions

- [ ] Implement state machine (waiting/listening/processing/responding)
- [ ] Handle user interruptions (stop bot when user speaks)
- [ ] Add Redis caching for conversation state
- [ ] Implement cleanup on disconnect

**Deliverable:** Robust conversation state handling

### Phase 7: API Integration (Day 13)

**Goal:** Connect bot service to API endpoints

- [ ] Update conversation routes to start/stop bots
- [ ] Add bot status monitoring endpoints
- [ ] Implement graceful shutdown
- [ ] Add health checks for bot service

**Deliverable:** Full API integration

### Phase 8: Testing & Optimization (Days 14-15)

**Goal:** Ensure quality and performance

- [ ] End-to-end testing with real audio
- [ ] Load testing (10 concurrent conversations)
- [ ] Latency optimization (target < 3 seconds)
- [ ] Memory leak testing
- [ ] Add monitoring and alerts

**Deliverable:** Production-ready bot service

### Phase 9: Documentation (Day 16)

**Goal:** Complete documentation

- [ ] API documentation updates
- [ ] Architecture diagrams
- [ ] Deployment guide
- [ ] Troubleshooting guide

**Deliverable:** Complete documentation

## Testing Strategy

### Unit Tests

```python
# tests/test_daily_bot_service.py

@pytest.mark.asyncio
async def test_create_bot_for_room():
    """Test bot creation and room joining."""
    service = DailyBotService()
    bot = await service.create_bot_for_room(
        room_url="https://test.daily.co/test-room",
        conversation_id="test-123"
    )
    assert bot is not None
    assert bot.is_running

@pytest.mark.asyncio
async def test_audio_processing_pipeline():
    """Test audio chunk processing."""
    pipeline = VoiceProcessingPipeline(
        conversation_id="test-123",
        client=Mock()
    )

    # Simulate audio chunk
    audio_data = {
        'buffer': b'\x00' * 32000,  # 1 second at 16kHz
        'sample_rate': 16000,
        'num_channels': 1
    }

    await pipeline.process_audio_chunk(audio_data)
    # Verify STT was called
```

### Integration Tests

```python
# tests/integration/test_daily_bot_integration.py

@pytest.mark.asyncio
async def test_full_conversation_flow():
    """Test complete conversation flow."""
    # 1. Create room
    response = await client.post(
        "/api/v1/conversations/daily/room",
        headers={"x-user-id": "test-user"}
    )
    data = response.json()

    # 2. Verify bot joined
    bot = daily_bot_service.get_bot(data["conversation_id"])
    assert bot is not None

    # 3. Simulate audio input
    # ...

    # 4. Verify response generated
    # ...

    # 5. End conversation
    await client.patch(
        f"/api/v1/conversations/{data['conversation_id']}"
    )

    # 6. Verify bot cleaned up
    bot = daily_bot_service.get_bot(data["conversation_id"])
    assert bot is None
```

### Load Tests

```python
# tests/load/test_concurrent_bots.py

@pytest.mark.asyncio
async def test_10_concurrent_conversations():
    """Test 10 simultaneous conversations."""
    tasks = []
    for i in range(10):
        task = asyncio.create_task(run_conversation(f"user-{i}"))
        tasks.append(task)

    results = await asyncio.gather(*tasks)

    # All conversations should complete successfully
    assert all(r["success"] for r in results)
```

## Security Considerations

1. **Token Security**
   - Bot uses service token, not user tokens
   - Tokens expire after 1 hour
   - Validate conversation ownership before processing

2. **Audio Data Privacy**
   - Audio never persisted to disk (processed in memory)
   - Only transcriptions stored in database
   - GDPR-compliant data retention policies

3. **Rate Limiting**
   - Limit concurrent bots per user
   - Rate limit conversation creation
   - Azure OpenAI quota monitoring

4. **Resource Protection**
   - Memory limits per bot instance
   - Automatic cleanup on timeout
   - Circuit breakers for external APIs

## Monitoring & Observability

### Metrics to Track

- Bot lifecycle events (created, joined, left, errors)
- Audio processing metrics (chunks received, buffer size)
- STT latency and error rates
- Agent response times
- TTS synthesis times
- End-to-end conversation latency
- Memory usage per bot
- Concurrent bot count

### Logging Strategy

```python
logger.info(f"[{conversation_id}] Bot joined room: {room_url}")
logger.info(f"[{conversation_id}] Audio chunk received: {len(audio_data)} bytes")
logger.info(f"[{conversation_id}] STT result: {transcription.text}")
logger.info(f"[{conversation_id}] Agent response: {response}")
logger.error(f"[{conversation_id}] Error in pipeline: {error}")
```

### Alerts

- Bot creation failures
- High STT error rates (> 5%)
- Slow response times (> 5 seconds)
- Memory leaks (increasing memory over time)
- Daily.co connection failures

## Deployment Strategy

### Prerequisites

- Daily.co account and API key
- Azure OpenAI deployment configured
- ElevenLabs API key configured
- Redis instance running

### Deployment Steps

1. **Update Dependencies**
   ```bash
   pip install daily-python
   ```

2. **Set Environment Variables**
   ```bash
   export DAILY_API_KEY=your_key_here
   ```

3. **Database Migrations**
   ```bash
   alembic upgrade head  # No new migrations needed
   ```

4. **Deploy Backend**
   ```bash
   docker build -t numeroly-api:latest .
   docker push numeroly-api:latest
   ```

5. **Restart Services**
   ```bash
   kubectl rollout restart deployment/numeroly-api
   ```

6. **Verify Health**
   ```bash
   curl https://api.numeroly.com/health
   ```

### Rollback Plan

If issues occur:
1. Revert to previous Docker image
2. Bot service degrades gracefully (rooms still created)
3. Frontend can fall back to file upload method

## Success Metrics

- ✅ Bot successfully joins 100% of created rooms
- ✅ Audio reception rate > 99.9%
- ✅ STT accuracy > 95% for Vietnamese
- ✅ End-to-end latency < 3 seconds (P95)
- ✅ Support 10 concurrent conversations
- ✅ Memory usage < 500MB per bot
- ✅ Zero crashes during 24-hour load test

## Future Enhancements (Post-MVP)

1. **Multi-turn Conversation Awareness**
   - Track conversation history across turns
   - Context-aware responses

2. **Voice Activity Detection (VAD)**
   - Detect when user starts/stops speaking
   - Reduce unnecessary processing

3. **Speaker Diarization**
   - Support multiple users in room
   - Identify who is speaking

4. **Real-time Transcription Display**
   - Show partial transcriptions as user speaks
   - Live captions

5. **Audio Recording Export**
   - Save conversation audio to Azure Blob Storage
   - Provide download links

## References

- [Daily.co Python SDK Documentation](https://docs.daily.co/reference/daily-python)
- [Daily.co WebRTC Guide](https://docs.daily.co/guides/products/webrtc)
- [Azure OpenAI STT Documentation](https://learn.microsoft.com/azure/ai-services/openai/whisper-quickstart)
- [Microsoft Agent Framework](https://microsoft.github.io/agent-framework/)
- [ElevenLabs Python SDK](https://github.com/elevenlabs/elevenlabs-python)

---

**Document Version:** 1.0
**Last Updated:** October 21, 2025
**Author:** Claude Code
**Reviewers:** TBD

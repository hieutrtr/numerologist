# Story 1.2d: Daily.co Bot Participant with Pipecat Framework (REVISED)

**Status:** Planning
**Priority:** P0 - Critical
**Story Points:** 8 (reduced from 13 due to Pipecat)
**Dependencies:** Story 1.2c (Daily.co Frontend Integration - Complete)
**Framework Decision:** Pipecat (see `docs/architecture/daily-python-vs-pipecat-comparison.md`)

## Revision Notes

**Original Plan:** 16 days using daily-python SDK (low-level implementation)
**Revised Plan:** 9 days using Pipecat framework (high-level pipeline)

**Key Changes:**
- Using Pipecat's pipeline architecture instead of custom daily-python implementation
- Built-in audio buffering, turn detection, and service orchestration
- 81% less custom code required (~190 lines vs ~1000 lines)
- 44% faster development timeline
- Leveraging pre-built integrations for Azure OpenAI and ElevenLabs

## Overview

Implement a Daily.co bot participant using the **Pipecat framework** that joins voice rooms, receives real-time audio streams from users, processes them through Azure OpenAI STT, sends to AI agent for numerology analysis, and responds with synthesized voice via ElevenLabs TTS.

## Problem Statement

Currently, the backend can create Daily.co rooms and generate tokens, but **cannot receive or process audio streams**. The frontend is ready to send audio via Daily.co WebRTC, but there's no backend participant to receive it.

**Current Gap:**
```
Frontend (Ready) → Daily.co Room (Created) → [NO BOT TO RECEIVE AUDIO] ❌
```

**Required Flow with Pipecat:**
```
Frontend → Daily.co Room → Pipecat Bot Pipeline → Response ✅
                                    ↓
                          ┌─────────┴──────────┐
                          │  Pipecat Pipeline  │
                          │  1. DailyTransport │
                          │  2. AzureSTTService│
                          │  3. AgentProcessor │
                          │  4. ElevenLabsTTS  │
                          └────────────────────┘
```

## Acceptance Criteria

### 1. Pipecat Bot Service Implementation
- [ ] `PipecatBotService` singleton class manages bot lifecycle
- [ ] Bot creates Pipecat pipeline when conversation starts
- [ ] Bot joins Daily.co room via DailyTransport
- [ ] Bot leaves room when conversation ends
- [ ] Proper cleanup of pipeline resources
- [ ] Handles reconnection automatically (Pipecat built-in)

### 2. Pipeline Configuration
- [ ] DailyTransport configured with room URL and token
- [ ] AzureSTTService configured for Vietnamese (`vi-VN`)
- [ ] Custom AgentProcessor wraps Microsoft Agent Framework
- [ ] ElevenLabsTTSService configured with Vietnamese voice
- [ ] Pipeline components connected in correct order

### 3. Audio Stream Reception (Automatic via Pipecat)
- [ ] DailyTransport receives audio chunks automatically
- [ ] Built-in phrase endpointing for turn detection
- [ ] Audio buffering handled by framework
- [ ] Handles multiple concurrent conversations (one pipeline per room)

### 4. Speech-to-Text Integration (Pre-built)
- [ ] Azure OpenAI STT via `pipecat.services.azure.AzureSTTService`
- [ ] Configured with `gpt-4o-mini-transcribe` deployment
- [ ] Vietnamese language support (`vi-VN`)
- [ ] Automatic streaming transcription
- [ ] Built-in error handling and retry logic

### 5. Custom Agent Processor
- [ ] `NumerologyAgentProcessor` class extends Pipecat's processor pattern
- [ ] Receives transcribed text from pipeline
- [ ] Integrates with Microsoft Agent Framework
- [ ] Calls numerology calculation tools
- [ ] Generates Vietnamese response text
- [ ] Maintains conversation context across turns

### 6. Text-to-Speech Response (Pre-built)
- [ ] ElevenLabs TTS via `pipecat.services.elevenlabs.ElevenLabsTTSService`
- [ ] Vietnamese voice synthesis
- [ ] Audio response sent back through DailyTransport
- [ ] Automatic audio streaming to user

### 7. Conversation State Management
- [ ] Track pipeline state via Pipecat events
- [ ] Store transcriptions and responses in database
- [ ] Cache conversation context in Redis
- [ ] Handle user interruptions (built-in with phrase endpointing)

### 8. Error Handling & Recovery
- [ ] Pipecat's built-in connection recovery
- [ ] Custom error handlers for agent failures
- [ ] Logging via Pipecat's event system
- [ ] Monitoring metrics from pipeline

### 9. Performance Requirements
- [ ] End-to-end latency < 3 seconds (user speech → bot response)
- [ ] Support up to 10 concurrent pipelines
- [ ] Audio quality: 16kHz sample rate (Pipecat default)
- [ ] Memory usage < 600MB per pipeline

## Technical Specification

### Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                         FastAPI Backend                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                   │
│  ┌────────────────────────────────────────────────────────┐    │
│  │           PipecatBotService (Singleton)                 │    │
│  │  - create_pipeline(room_url, conversation_id, token)   │    │
│  │  - destroy_pipeline(conversation_id)                    │    │
│  │  - get_pipeline_status(conversation_id)                 │    │
│  │  - _pipelines: Dict[str, PipelineRunner]               │    │
│  └───────────────────┬────────────────────────────────────┘    │
│                      │                                           │
│  ┌───────────────────▼────────────────────────────────────┐    │
│  │      Pipecat Pipeline (per conversation)                │    │
│  │                                                          │    │
│  │  ┌────────────────────────────────────────────────┐   │    │
│  │  │ 1. DailyTransport                               │   │    │
│  │  │    - Connects to Daily.co room                 │   │    │
│  │  │    - Receives audio from user                  │   │    │
│  │  │    - Sends audio to user                       │   │    │
│  │  │    - Handles WebRTC automatically              │   │    │
│  │  └──────────────────┬─────────────────────────────┘   │    │
│  │                     │ Audio Frames                     │    │
│  │  ┌──────────────────▼─────────────────────────────┐   │    │
│  │  │ 2. AzureSTTService                              │   │    │
│  │  │    - Transcribes audio to text                 │   │    │
│  │  │    - Vietnamese language support               │   │    │
│  │  │    - Built-in phrase endpointing               │   │    │
│  │  └──────────────────┬─────────────────────────────┘   │    │
│  │                     │ Text Frames                      │    │
│  │  ┌──────────────────▼─────────────────────────────┐   │    │
│  │  │ 3. NumerologyAgentProcessor (CUSTOM)            │   │    │
│  │  │    - Receives transcribed text                 │   │    │
│  │  │    - Calls Microsoft Agent Framework           │   │    │
│  │  │    - Uses numerology tools                     │   │    │
│  │  │    - Generates response text                   │   │    │
│  │  │    - Manages context                           │   │    │
│  │  └──────────────────┬─────────────────────────────┘   │    │
│  │                     │ Response Text Frames             │    │
│  │  ┌──────────────────▼─────────────────────────────┐   │    │
│  │  │ 4. ElevenLabsTTSService                         │   │    │
│  │  │    - Synthesizes Vietnamese voice              │   │    │
│  │  │    - Generates audio frames                    │   │    │
│  │  └──────────────────┬─────────────────────────────┘   │    │
│  │                     │ Audio Frames (Response)          │    │
│  │                     └──────────────────────────────────┘    │
│  │                                  │                           │
│  │                                  └─► Back to DailyTransport │
│  └─────────────────────────────────────────────────────────────┘
│                                                                   │
│  External Services:                                              │
│  - Azure OpenAI (STT): gpt-4o-mini-transcribe                   │
│  - Microsoft Agent Framework: Numerology tools                   │
│  - ElevenLabs: Vietnamese TTS                                   │
│  - Daily.co: WebRTC transport                                   │
│                                                                   │
└─────────────────────────────────────────────────────────────────┘

User (Frontend) ←─ Daily.co Room ─→ Backend Bot Pipeline
```

### Core Components

#### 1. PipecatBotService (Singleton)

Manages all bot pipelines across concurrent conversations.

```python
# apps/api/src/services/pipecat_bot_service.py

from typing import Dict, Optional
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.transports.daily import DailyTransport
from pipecat.services.azure import AzureSTTService
from pipecat.services.elevenlabs import ElevenLabsTTSService

from src.services.agent_service import AgentService
from src.utils.database import get_session
from src.utils.redis_client import get_redis
from src.config import config

class PipecatBotService:
    """
    Singleton service that manages Pipecat pipelines for Daily.co voice conversations.

    Each conversation gets its own pipeline instance with:
    - DailyTransport (WebRTC audio streaming)
    - AzureSTTService (Speech-to-Text)
    - NumerologyAgentProcessor (AI agent)
    - ElevenLabsTTSService (Text-to-Speech)
    """

    _instance: Optional['PipecatBotService'] = None
    _pipelines: Dict[str, PipelineRunner] = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    async def create_pipeline(
        self,
        room_url: str,
        conversation_id: str,
        token: str,
        user_id: str
    ) -> PipelineRunner:
        """
        Create and start a Pipecat pipeline for a conversation.

        Args:
            room_url: Daily.co room URL (e.g., https://yourdomain.daily.co/room-name)
            conversation_id: Unique conversation ID
            token: Daily.co meeting token
            user_id: User ID for this conversation

        Returns:
            PipelineRunner instance
        """
        if conversation_id in self._pipelines:
            raise ValueError(f"Pipeline already exists for conversation {conversation_id}")

        # Configure transport
        daily_transport = DailyTransport(
            room_url=room_url,
            token=token,
            bot_name="Numeroly Assistant",
            enable_audio=True,
            enable_video=False,
        )

        # Configure STT
        azure_stt = AzureSTTService(
            api_key=config.AZURE_OPENAI_KEY,
            region=config.AZURE_OPENAI_REGION,
            deployment_name=config.AZURE_OPENAI_STT_DEPLOYMENT_NAME,
            language="vi-VN",
        )

        # Configure custom agent processor
        agent_processor = NumerologyAgentProcessor(
            conversation_id=conversation_id,
            user_id=user_id,
            agent_service=AgentService(),
            db_session=await get_session(),
            redis_client=await get_redis(),
        )

        # Configure TTS
        elevenlabs_tts = ElevenLabsTTSService(
            api_key=config.ELEVENLABS_API_KEY,
            voice_id=config.ELEVENLABS_VOICE_ID,
            model="eleven_multilingual_v2",
        )

        # Create pipeline
        pipeline = Pipeline([
            daily_transport,
            azure_stt,
            agent_processor,
            elevenlabs_tts,
        ])

        # Create runner
        runner = PipelineRunner(pipeline)

        # Store runner
        self._pipelines[conversation_id] = runner

        # Start pipeline
        await runner.run()

        return runner

    async def destroy_pipeline(self, conversation_id: str) -> None:
        """
        Stop and cleanup a pipeline.

        Args:
            conversation_id: Conversation ID
        """
        if conversation_id not in self._pipelines:
            raise ValueError(f"No pipeline found for conversation {conversation_id}")

        runner = self._pipelines[conversation_id]
        await runner.stop()
        del self._pipelines[conversation_id]

    def get_pipeline_status(self, conversation_id: str) -> Dict[str, any]:
        """
        Get pipeline status.

        Args:
            conversation_id: Conversation ID

        Returns:
            Status dictionary
        """
        if conversation_id not in self._pipelines:
            return {"status": "not_found"}

        runner = self._pipelines[conversation_id]
        return {
            "status": "running" if runner.is_running() else "stopped",
            "conversation_id": conversation_id,
        }

    async def destroy_all_pipelines(self) -> None:
        """
        Stop and cleanup all pipelines (for shutdown).
        """
        for conversation_id in list(self._pipelines.keys()):
            await self.destroy_pipeline(conversation_id)
```

#### 2. NumerologyAgentProcessor (Custom Processor)

Custom Pipecat processor that integrates with Microsoft Agent Framework.

```python
# apps/api/src/services/numerology_agent_processor.py

from typing import Optional
from pipecat.processors.frame_processor import FrameProcessor
from pipecat.frames.frames import TextFrame, ErrorFrame

from src.services.agent_service import AgentService
from src.models.conversation import Conversation, ConversationMessage
from src.utils.database import AsyncSession
from src.utils.redis_client import RedisClient
from src.utils.logger import get_logger

logger = get_logger(__name__)

class NumerologyAgentProcessor(FrameProcessor):
    """
    Custom Pipecat processor that integrates Microsoft Agent Framework
    for numerology calculations and Vietnamese conversations.

    Receives transcribed text from STT, processes through agent,
    and emits response text for TTS.
    """

    def __init__(
        self,
        conversation_id: str,
        user_id: str,
        agent_service: AgentService,
        db_session: AsyncSession,
        redis_client: RedisClient,
    ):
        super().__init__()
        self.conversation_id = conversation_id
        self.user_id = user_id
        self.agent_service = agent_service
        self.db_session = db_session
        self.redis_client = redis_client
        self.context = []  # Conversation history

    async def process_frame(self, frame):
        """
        Process frames from the pipeline.

        TextFrame from STT → Agent processing → TextFrame for TTS
        """
        # Only process text frames (transcriptions from STT)
        if not isinstance(frame, TextFrame):
            return await super().process_frame(frame)

        user_text = frame.text

        try:
            # Log user message
            logger.info(f"[{self.conversation_id}] User said: {user_text}")

            # Save user message to database
            await self._save_message(
                role="user",
                content=user_text,
            )

            # Add to context
            self.context.append({
                "role": "user",
                "content": user_text,
            })

            # Process through agent
            agent_response = await self.agent_service.process_message(
                user_id=self.user_id,
                conversation_id=self.conversation_id,
                message=user_text,
                context=self.context,
            )

            response_text = agent_response["response"]

            # Log agent response
            logger.info(f"[{self.conversation_id}] Agent responds: {response_text}")

            # Save agent response to database
            await self._save_message(
                role="assistant",
                content=response_text,
                metadata=agent_response.get("metadata", {}),
            )

            # Add to context
            self.context.append({
                "role": "assistant",
                "content": response_text,
            })

            # Cache context in Redis
            await self._cache_context()

            # Emit response text frame for TTS
            yield TextFrame(response_text)

        except Exception as e:
            logger.error(f"[{self.conversation_id}] Agent processing error: {e}")

            # Emit error frame
            yield ErrorFrame(str(e))

            # Emit fallback text frame
            yield TextFrame("Xin lỗi, tôi gặp sự cố khi xử lý yêu cầu của bạn. Vui lòng thử lại.")

    async def _save_message(
        self,
        role: str,
        content: str,
        metadata: Optional[dict] = None,
    ) -> None:
        """Save message to database."""
        message = ConversationMessage(
            conversation_id=self.conversation_id,
            role=role,
            content=content,
            metadata=metadata or {},
        )
        self.db_session.add(message)
        await self.db_session.commit()

    async def _cache_context(self) -> None:
        """Cache conversation context in Redis."""
        cache_key = f"conversation:{self.conversation_id}:context"
        await self.redis_client.set(
            cache_key,
            json.dumps(self.context),
            ex=3600,  # 1 hour TTL
        )
```

#### 3. API Endpoint Integration

Update conversation routes to use Pipecat bot service.

```python
# apps/api/src/routes/conversations.py

from fastapi import APIRouter, Depends, HTTPException
from src.services.pipecat_bot_service import PipecatBotService
from src.services.conversation_service import ConversationService
from src.schemas.conversation import ConversationCreate, ConversationResponse

router = APIRouter(prefix="/v1/conversations", tags=["conversations"])

@router.post("/", response_model=ConversationResponse)
async def create_conversation_with_bot(
    request: ConversationCreate,
    bot_service: PipecatBotService = Depends(lambda: PipecatBotService()),
    conversation_service: ConversationService = Depends(),
):
    """
    Create a new conversation and start a Pipecat bot pipeline.

    This endpoint:
    1. Creates a Daily.co room
    2. Generates a token
    3. Creates a conversation record
    4. Starts a Pipecat pipeline (bot joins room)
    """
    # Create Daily.co room
    room = await conversation_service.create_daily_room(
        room_config={"enable_chat": False, "enable_screenshare": False}
    )

    room_url = room["url"]
    room_name = room["name"]

    # Generate token
    token = await conversation_service.create_meeting_token(
        room_url=room_url,
        user_id=request.user_id,
    )

    # Create conversation
    conversation = await conversation_service.create_conversation(
        user_id=request.user_id,
        room_url=room_url,
        room_name=room_name,
    )

    # Start Pipecat pipeline (bot joins room)
    try:
        await bot_service.create_pipeline(
            room_url=room_url,
            conversation_id=str(conversation.id),
            token=token,
            user_id=request.user_id,
        )
    except Exception as e:
        # Cleanup conversation if bot fails to join
        await conversation_service.delete_conversation(conversation.id)
        raise HTTPException(
            status_code=500,
            detail=f"Failed to start bot pipeline: {str(e)}"
        )

    return ConversationResponse(
        id=str(conversation.id),
        user_id=conversation.user_id,
        room_url=room_url,
        token=token,
        status="active",
        created_at=conversation.created_at,
    )

@router.patch("/{conversation_id}")
async def end_conversation(
    conversation_id: str,
    bot_service: PipecatBotService = Depends(lambda: PipecatBotService()),
    conversation_service: ConversationService = Depends(),
):
    """
    End a conversation and stop the Pipecat pipeline.
    """
    # Stop pipeline
    try:
        await bot_service.destroy_pipeline(conversation_id)
    except ValueError:
        # Pipeline already stopped or not found
        pass

    # Update conversation status
    await conversation_service.end_conversation(conversation_id)

    return {"status": "ended"}

@router.get("/{conversation_id}/status")
async def get_conversation_status(
    conversation_id: str,
    bot_service: PipecatBotService = Depends(lambda: PipecatBotService()),
):
    """
    Get pipeline status for a conversation.
    """
    status = bot_service.get_pipeline_status(conversation_id)
    return status
```

### Dependencies

**Python Packages (add to `apps/api/requirements.txt`):**

```txt
# Pipecat framework
pipecat-ai==0.1.0

# Pipecat services (if not included in main package)
pipecat-ai[azure]==0.1.0
pipecat-ai[elevenlabs]==0.1.0
pipecat-ai[daily]==0.1.0

# WebRTC support (required by Pipecat)
aiortc==1.9.0
av==12.0.0

# Keep existing dependencies
daily-python>=0.10.0
azure-cognitiveservices-speech>=1.40.0
elevenlabs>=0.4.0
openai>=1.60.0
```

**Configuration (add to `apps/api/src/config.py`):**

```python
# Pipecat-specific configuration
PIPECAT_LOG_LEVEL = os.getenv("PIPECAT_LOG_LEVEL", "INFO")
PIPECAT_MAX_PIPELINES = int(os.getenv("PIPECAT_MAX_PIPELINES", "10"))
```

### Database Schema Updates

No changes required - existing `conversations` and `conversation_messages` tables already support this implementation.

### Performance Characteristics

**Expected Latency Breakdown:**

| Component | Latency | Notes |
|-----------|---------|-------|
| DailyTransport (audio reception) | ~50ms | WebRTC buffering |
| AzureSTTService (transcription) | ~200-500ms | Streaming STT |
| NumerologyAgentProcessor | ~500-1000ms | Agent + tools |
| ElevenLabsTTSService | ~300-800ms | TTS synthesis |
| DailyTransport (audio send) | ~50ms | WebRTC buffering |
| **Total End-to-End** | **~1.1-2.4s** | Well under 3s requirement |

**Memory Usage:**
- Pipecat pipeline overhead: ~150MB
- Azure STT service: ~50MB
- ElevenLabs TTS: ~50MB
- Agent processor: ~100MB
- **Total per pipeline: ~350MB** (under 600MB limit)

**Concurrent Pipelines:**
- Max recommended: 10 pipelines
- Total memory: ~3.5GB
- CPU usage: ~50-70% (4 cores)

## Implementation Plan

### Phase 1: Environment Setup (Day 1)

**Tasks:**
1. Install Pipecat and dependencies
2. Update requirements.txt
3. Configure logging for Pipecat
4. Test basic Pipecat pipeline locally

**Deliverables:**
- [ ] Pipecat installed in backend environment
- [ ] Basic "hello world" pipeline working
- [ ] Documentation on Pipecat setup

**Acceptance:**
- Can create and run simple Pipecat pipeline
- All dependencies resolved

### Phase 2: PipecatBotService Implementation (Day 2)

**Tasks:**
1. Create `PipecatBotService` singleton class
2. Implement `create_pipeline()` method
3. Implement `destroy_pipeline()` method
4. Add pipeline status tracking
5. Write unit tests

**Deliverables:**
- [ ] `src/services/pipecat_bot_service.py` created
- [ ] Unit tests passing
- [ ] Can create/destroy pipelines

**Acceptance:**
- Service manages multiple pipelines
- Proper cleanup on destroy

### Phase 3: DailyTransport Integration (Day 3)

**Tasks:**
1. Configure DailyTransport with room URL and token
2. Test bot joining Daily.co rooms
3. Verify audio reception
4. Handle transport errors

**Deliverables:**
- [ ] Bot successfully joins Daily.co rooms
- [ ] Audio frames received from user
- [ ] Error handling for connection failures

**Acceptance:**
- Bot appears in Daily.co room
- Can receive audio from user's microphone

### Phase 4: Azure STT Integration (Day 4)

**Tasks:**
1. Configure AzureSTTService for Vietnamese
2. Connect STT to pipeline
3. Test transcription accuracy
4. Tune endpointing settings

**Deliverables:**
- [ ] STT transcribing Vietnamese speech
- [ ] Text frames flowing through pipeline
- [ ] Good transcription accuracy

**Acceptance:**
- Vietnamese phrases transcribed correctly
- Turn detection working (phrase endpointing)

### Phase 5: Custom Agent Processor (Days 5-6)

**Tasks:**
1. Create `NumerologyAgentProcessor` class
2. Integrate with existing `AgentService`
3. Implement context management
4. Add database message saving
5. Add Redis context caching
6. Write unit tests

**Deliverables:**
- [ ] `src/services/numerology_agent_processor.py` created
- [ ] Agent processing transcribed text
- [ ] Responses generated correctly
- [ ] Unit tests passing

**Acceptance:**
- Agent receives user text and responds
- Context maintained across turns
- Messages saved to database

### Phase 6: ElevenLabs TTS Integration (Day 7)

**Tasks:**
1. Configure ElevenLabsTTSService
2. Test Vietnamese voice synthesis
3. Verify audio quality
4. Connect TTS output to DailyTransport

**Deliverables:**
- [ ] TTS synthesizing Vietnamese responses
- [ ] Audio sent back through Daily.co
- [ ] User receives voice responses

**Acceptance:**
- User hears bot responses in Daily.co room
- Voice quality is good
- Latency acceptable

### Phase 7: API Endpoint Updates (Day 8)

**Tasks:**
1. Update `/v1/conversations/` endpoint to start pipeline
2. Update `/v1/conversations/{id}` endpoint to stop pipeline
3. Add `/v1/conversations/{id}/status` endpoint
4. Update conversation service integration
5. Write integration tests

**Deliverables:**
- [ ] API endpoints working with Pipecat
- [ ] Integration tests passing
- [ ] API documentation updated

**Acceptance:**
- Can create conversation and bot joins room
- Can end conversation and bot leaves
- Status endpoint returns correct info

### Phase 8: Testing & Optimization (Day 9)

**Tasks:**
1. End-to-end testing with frontend
2. Load testing (10 concurrent conversations)
3. Latency optimization
4. Memory profiling
5. Error scenario testing
6. Documentation

**Deliverables:**
- [ ] All acceptance criteria met
- [ ] Performance requirements satisfied
- [ ] Documentation complete
- [ ] Known issues documented

**Acceptance:**
- Full voice conversation flow working
- Latency < 3 seconds
- 10 concurrent conversations supported
- No critical bugs

## Testing Strategy

### Unit Tests

```python
# tests/test_pipecat_bot_service.py

import pytest
from src.services.pipecat_bot_service import PipecatBotService

@pytest.mark.asyncio
async def test_create_pipeline():
    """Test creating a pipeline."""
    service = PipecatBotService()

    runner = await service.create_pipeline(
        room_url="https://test.daily.co/test-room",
        conversation_id="test-conv-123",
        token="test-token",
        user_id="user-123",
    )

    assert runner is not None
    assert service.get_pipeline_status("test-conv-123")["status"] == "running"

    # Cleanup
    await service.destroy_pipeline("test-conv-123")

@pytest.mark.asyncio
async def test_destroy_pipeline():
    """Test destroying a pipeline."""
    service = PipecatBotService()

    await service.create_pipeline(
        room_url="https://test.daily.co/test-room",
        conversation_id="test-conv-123",
        token="test-token",
        user_id="user-123",
    )

    await service.destroy_pipeline("test-conv-123")

    status = service.get_pipeline_status("test-conv-123")
    assert status["status"] == "not_found"
```

```python
# tests/test_numerology_agent_processor.py

import pytest
from src.services.numerology_agent_processor import NumerologyAgentProcessor
from pipecat.frames.frames import TextFrame

@pytest.mark.asyncio
async def test_process_text_frame(mock_agent_service, mock_db_session, mock_redis):
    """Test processing a text frame through agent."""
    processor = NumerologyAgentProcessor(
        conversation_id="test-conv-123",
        user_id="user-123",
        agent_service=mock_agent_service,
        db_session=mock_db_session,
        redis_client=mock_redis,
    )

    # Mock agent response
    mock_agent_service.process_message.return_value = {
        "response": "Số chủ đạo của bạn là 3",
        "metadata": {"life_path": 3},
    }

    # Process frame
    input_frame = TextFrame("Tên tôi là Nguyễn Văn A, sinh ngày 15/3/1990")
    output_frames = []

    async for frame in processor.process_frame(input_frame):
        output_frames.append(frame)

    # Verify
    assert len(output_frames) == 1
    assert isinstance(output_frames[0], TextFrame)
    assert "Số chủ đạo" in output_frames[0].text

    # Verify agent was called
    mock_agent_service.process_message.assert_called_once()
```

### Integration Tests

```python
# tests/integration/test_full_pipeline.py

import pytest
from src.services.pipecat_bot_service import PipecatBotService

@pytest.mark.integration
@pytest.mark.asyncio
async def test_full_voice_pipeline(daily_room, daily_token):
    """Test full voice pipeline from audio to response."""
    service = PipecatBotService()

    # Create pipeline
    runner = await service.create_pipeline(
        room_url=daily_room,
        conversation_id="integration-test",
        token=daily_token,
        user_id="test-user",
    )

    # Wait for bot to join room
    await asyncio.sleep(2)

    # Simulate user speaking (requires Daily.co test client)
    # This would use a test client to send audio
    # (Implementation depends on Daily.co testing tools)

    # Verify bot responds
    # (Check that audio is received from bot)

    # Cleanup
    await service.destroy_pipeline("integration-test")
```

### Manual Testing Checklist

- [ ] Bot joins Daily.co room from mobile app
- [ ] Bot shows as participant in room
- [ ] User can speak and bot transcribes correctly
- [ ] Bot responds with voice after ~2 seconds
- [ ] Bot's Vietnamese voice is clear and natural
- [ ] Multiple users can have concurrent conversations
- [ ] Bot handles user interruptions gracefully
- [ ] Bot leaves room when conversation ends
- [ ] Error messages displayed for failures

## Deployment

### Environment Variables

```bash
# .env additions
PIPECAT_LOG_LEVEL=INFO
PIPECAT_MAX_PIPELINES=10
```

### Docker Configuration

```dockerfile
# apps/api/Dockerfile additions

# Install system dependencies for Pipecat/aiortc
RUN apt-get update && apt-get install -y \
    libavformat-dev \
    libavcodec-dev \
    libavdevice-dev \
    libavutil-dev \
    libswscale-dev \
    libswresample-dev \
    libavfilter-dev \
    libopus-dev \
    libvpx-dev \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
RUN pip install -r requirements.txt
```

### Resource Limits

```yaml
# docker-compose.yml
services:
  api:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
```

## Monitoring

### Key Metrics

1. **Pipeline Health:**
   - Active pipelines count
   - Pipeline creation rate
   - Pipeline failure rate

2. **Performance:**
   - End-to-end latency (P50, P95, P99)
   - STT latency
   - Agent processing latency
   - TTS latency

3. **Resource Usage:**
   - Memory per pipeline
   - CPU usage
   - Network bandwidth

### Logging

```python
# Structured logging for Pipecat events

logger.info(
    "Pipeline created",
    extra={
        "conversation_id": conversation_id,
        "room_url": room_url,
        "user_id": user_id,
    }
)

logger.info(
    "User message",
    extra={
        "conversation_id": conversation_id,
        "text": user_text,
        "timestamp": datetime.utcnow().isoformat(),
    }
)

logger.info(
    "Agent response",
    extra={
        "conversation_id": conversation_id,
        "text": response_text,
        "latency_ms": latency_ms,
    }
)
```

## Risks & Mitigation

### Risk 1: Pipecat Framework Stability
**Impact:** High
**Probability:** Low
**Mitigation:**
- Pipecat is backed by Daily.co (reputable company)
- Active community (5000+ GitHub stars)
- Can fall back to daily-python if needed

### Risk 2: Memory Usage Higher Than Expected
**Impact:** Medium
**Probability:** Medium
**Mitigation:**
- Monitor memory closely during testing
- Implement pipeline limits (max 10 concurrent)
- Add pipeline timeout and cleanup

### Risk 3: Vietnamese STT/TTS Quality
**Impact:** High
**Probability:** Low
**Mitigation:**
- Azure OpenAI has good Vietnamese support (tested in 1.2c)
- ElevenLabs Vietnamese voices are high quality
- Can tune STT/TTS settings if needed

### Risk 4: Latency Exceeds 3 Seconds
**Impact:** Medium
**Probability:** Low
**Mitigation:**
- Pipecat is optimized for low latency
- Can tune buffering and endpointing settings
- Azure/ElevenLabs APIs are fast (<1s each)

## Success Criteria

**Must Have (MVP):**
- [ ] User can speak to bot via Daily.co
- [ ] Bot transcribes Vietnamese speech correctly
- [ ] Bot responds with Vietnamese voice
- [ ] End-to-end latency < 3 seconds
- [ ] Supports 3 concurrent conversations minimum

**Should Have:**
- [ ] Supports 10 concurrent conversations
- [ ] Context maintained across multiple turns
- [ ] Graceful error handling with fallback messages
- [ ] Comprehensive logging for debugging

**Nice to Have:**
- [ ] Advanced metrics and monitoring
- [ ] User interruption handling
- [ ] Voice quality tuning options

## Documentation

### User-Facing Documentation
- How voice conversations work
- Troubleshooting voice issues
- Privacy and data handling

### Developer Documentation
- Pipecat architecture overview
- How to modify agent processor
- How to add new pipeline components
- Performance tuning guide

## Related Documentation

- See `docs/architecture/daily-python-vs-pipecat-comparison.md` for framework comparison
- See `docs/stories/1.2c-voice-streaming.md` for frontend implementation
- See `docs/architecture/tech-stack.md` for overall architecture

---

**Document Version:** 2.0 (Pipecat Revision)
**Original Version:** 1.0 (daily-python, 16 days)
**Revised:** October 21, 2025
**Estimated Timeline:** 9 days (44% faster)
**Estimated LOC:** ~190 lines (81% less code)
**Framework:** Pipecat v0.1.0
